{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namanshijain/genrative-ai/blob/main/naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "53RH9IKszXqZ"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # for data visualization purposes\n",
        "import seaborn as sns # for statistical data visualization\n",
        "%matplotlib inline\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "AEd87wY8zXqZ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZxOsZC_zXqZ"
      },
      "source": [
        "# **6. Import dataset** <a class=\"anchor\" id=\"6\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "XFiM8NknzXqZ"
      },
      "outputs": [],
      "source": [
        "data = '/kaggle/input/adult-dataset/adult.csv'\n",
        "\n",
        "df = pd.read_csv(data, header=None, sep=',\\s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3xt27rYzXqa"
      },
      "source": [
        "# **7. Exploratory data analysis** <a class=\"anchor\" id=\"7\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)\n",
        "\n",
        "\n",
        "Now, I will explore the data to gain insights about the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "2SWfgFm9zXqa"
      },
      "outputs": [],
      "source": [
        "# view dimensions of dataset\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxV9a66AzXqa"
      },
      "source": [
        "We can see that there are 32561 instances and 15 attributes in the data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNTWGsfGzXqa"
      },
      "source": [
        "### View top 5 rows of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "97r3mfNuzXqa"
      },
      "outputs": [],
      "source": [
        "# preview the dataset\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm8tJcolzXqa"
      },
      "source": [
        "### Rename column names\n",
        "\n",
        "We can see that the dataset does not have proper column names. The columns are merely labelled as 0,1,2.... and so on. We should give proper names to the columns. I will do it as follows:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "LpEkHrVKzXqa"
      },
      "outputs": [],
      "source": [
        "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\n",
        "             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
        "\n",
        "df.columns = col_names\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "g_cNT0vTzXqa"
      },
      "outputs": [],
      "source": [
        "# let's again preview the dataset\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1ABdmmHzXqa"
      },
      "source": [
        "We can see that the column names are renamed. Now, the columns have meaningful names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro8hw4SJzXqb"
      },
      "source": [
        "### View summary of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "Z1zXQGsczXqb"
      },
      "outputs": [],
      "source": [
        "# view summary of dataset\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJxdbFCEzXqb"
      },
      "source": [
        "We can see that there are no missing values in the dataset. I will confirm this further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP3fNoYvzXqb"
      },
      "source": [
        "### Explore categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "fHaw5HkhzXqb"
      },
      "outputs": [],
      "source": [
        "# find categorical variables\n",
        "\n",
        "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
        "\n",
        "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
        "\n",
        "print('The categorical variables are :\\n\\n', categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "QZz5JvgozXqb"
      },
      "outputs": [],
      "source": [
        "# view the categorical variables\n",
        "\n",
        "df[categorical].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkatrFfrzXqb"
      },
      "source": [
        "### Explore problems within categorical variables\n",
        "\n",
        "\n",
        "First, I will explore the categorical variables.\n",
        "\n",
        "\n",
        "### Missing values in categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "nOSjBFIhzXqb"
      },
      "outputs": [],
      "source": [
        "# check missing values in categorical variables\n",
        "\n",
        "df[categorical].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAiDp07izXqb"
      },
      "source": [
        "We can see that there are no missing values in the categorical variables. I will confirm this further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "H_UmvvU4zXqb"
      },
      "outputs": [],
      "source": [
        "# view frequency counts of values in categorical variables\n",
        "\n",
        "for var in categorical:\n",
        "\n",
        "    print(df[var].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "VzZtmwrnzXqb"
      },
      "outputs": [],
      "source": [
        "# view frequency distribution of categorical variables\n",
        "\n",
        "for var in categorical:\n",
        "\n",
        "    print(df[var].value_counts()/np.float(len(df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtxqXys2zXqc"
      },
      "source": [
        "Now, we can see that there are several variables like `workclass`, `occupation` and `native_country` which contain missing values. Generally, the missing values are coded as `NaN` and python will detect them with the usual command of `df.isnull().sum()`.\n",
        "\n",
        "But, in this case the missing values are coded as `?`. Python fail to detect these as missing values because it do not consider `?` as missing values. So, I have to replace `?` with `NaN` so that Python can detect these missing values.\n",
        "\n",
        "I will explore these variables and replace `?` with `NaN`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP55LDerzXqc"
      },
      "source": [
        "### Explore workclass variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "IkSAX1N1zXqc"
      },
      "outputs": [],
      "source": [
        "# check labels in workclass variable\n",
        "\n",
        "df.workclass.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "2_vxX4grzXqc"
      },
      "outputs": [],
      "source": [
        "# check frequency distribution of values in workclass variable\n",
        "\n",
        "df.workclass.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcyOYtizzXqc"
      },
      "source": [
        "We can see that there are 1836 values encoded as `?` in workclass variable. I will replace these `?` with `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "qTE-fy2HzXqc"
      },
      "outputs": [],
      "source": [
        "# replace '?' values in workclass variable with `NaN`\n",
        "\n",
        "\n",
        "df['workclass'].replace('?', np.NaN, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "Whph5z3LzXqc"
      },
      "outputs": [],
      "source": [
        "# again check the frequency distribution of values in workclass variable\n",
        "\n",
        "df.workclass.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdpK8tsnzXqc"
      },
      "source": [
        "Now, we can see that there are no values encoded as `?` in the `workclass` variable.\n",
        "\n",
        "I will adopt similar approach with `occupation` and `native_country` column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMdbUZeYzXqc"
      },
      "source": [
        "### Explore occupation variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "SuQSrY7RzXqc"
      },
      "outputs": [],
      "source": [
        "# check labels in occupation variable\n",
        "\n",
        "df.occupation.unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "edaCrHdIzXqc"
      },
      "outputs": [],
      "source": [
        "# check frequency distribution of values in occupation variable\n",
        "\n",
        "df.occupation.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UovaQ75XzXqd"
      },
      "source": [
        "We can see that there are 1843 values encoded as `?` in `occupation` variable. I will replace these `?` with `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "HGhPDYUSzXqd"
      },
      "outputs": [],
      "source": [
        "# replace '?' values in occupation variable with `NaN`\n",
        "\n",
        "df['occupation'].replace('?', np.NaN, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "pscuL1V6zXqg"
      },
      "outputs": [],
      "source": [
        "# again check the frequency distribution of values in occupation variable\n",
        "\n",
        "df.occupation.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qhqe6dvzXqg"
      },
      "source": [
        "### Explore native_country variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "CgrDVUcizXqg"
      },
      "outputs": [],
      "source": [
        "# check labels in native_country variable\n",
        "\n",
        "df.native_country.unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "tW0smL_yzXqg"
      },
      "outputs": [],
      "source": [
        "# check frequency distribution of values in native_country variable\n",
        "\n",
        "df.native_country.value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KWAJ7CKzXqg"
      },
      "source": [
        "We can see that there are 583 values encoded as `?` in `native_country` variable. I will replace these `?` with `NaN`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "E2VVoQdYzXqg"
      },
      "outputs": [],
      "source": [
        "# replace '?' values in native_country variable with `NaN`\n",
        "\n",
        "df['native_country'].replace('?', np.NaN, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "ZJCfBqrxzXqh"
      },
      "outputs": [],
      "source": [
        "# again check the frequency distribution of values in native_country variable\n",
        "\n",
        "df.native_country.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejzHi7emzXqh"
      },
      "source": [
        "### Check missing values in categorical variables again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "jwAf-Dw2zXqh"
      },
      "outputs": [],
      "source": [
        "df[categorical].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFXTGwXLzXqh"
      },
      "source": [
        "Now, we can see that `workclass`, `occupation` and `native_country` variable contains missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4V0zFkqzXqh"
      },
      "source": [
        "### Number of labels: cardinality\n",
        "\n",
        "\n",
        "The number of labels within a categorical variable is known as **cardinality**. A high number of labels within a variable is known as **high cardinality**. High cardinality may pose some serious problems in the machine learning model. So, I will check for high cardinality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "kTEBk2N_zXqh"
      },
      "outputs": [],
      "source": [
        "# check for cardinality in categorical variables\n",
        "\n",
        "for var in categorical:\n",
        "\n",
        "    print(var, ' contains ', len(df[var].unique()), ' labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYFrGVy-zXqh"
      },
      "source": [
        "We can see that `native_country` column contains relatively large number of labels as compared to other columns. I will check for cardinality after train-test split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlDFmi75zXqh"
      },
      "source": [
        "### Explore Numerical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "DkjHXs5tzXqh"
      },
      "outputs": [],
      "source": [
        "# find numerical variables\n",
        "\n",
        "numerical = [var for var in df.columns if df[var].dtype!='O']\n",
        "\n",
        "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
        "\n",
        "print('The numerical variables are :', numerical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "gcVZsNm5zXqh"
      },
      "outputs": [],
      "source": [
        "# view the numerical variables\n",
        "\n",
        "df[numerical].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9FDBU0UzXqh"
      },
      "source": [
        "### Summary of numerical variables\n",
        "\n",
        "\n",
        "- There are 6 numerical variables.\n",
        "\n",
        "\n",
        "- These are given by `age`, `fnlwgt`, `education_num`, `capital_gain`, `capital_loss` and `hours_per_week`.\n",
        "\n",
        "\n",
        "- All of the numerical variables are of discrete data type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAnV2YBEzXqi"
      },
      "source": [
        "### Explore problems within numerical variables\n",
        "\n",
        "\n",
        "Now, I will explore the numerical variables.\n",
        "\n",
        "\n",
        "### Missing values in numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "THE7BXpMzXqi"
      },
      "outputs": [],
      "source": [
        "# check missing values in numerical variables\n",
        "\n",
        "df[numerical].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1CLwABezXqi"
      },
      "source": [
        "We can see that all the 6 numerical variables do not contain missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmkZ2SAuzXqi"
      },
      "source": [
        "# **8. Declare feature vector and target variable** <a class=\"anchor\" id=\"8\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "ewJNsf7AzXqi"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['income'], axis=1)\n",
        "\n",
        "y = df['income']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF9Acql0zXqi"
      },
      "source": [
        "# **9. Split data into separate training and test set** <a class=\"anchor\" id=\"9\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "qmM_hgzyzXqi"
      },
      "outputs": [],
      "source": [
        "# split X and y into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "7RC7OchOzXqi"
      },
      "outputs": [],
      "source": [
        "# check the shape of X_train and X_test\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDPArj4fzXqi"
      },
      "source": [
        "# **10. Feature Engineering** <a class=\"anchor\" id=\"10\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)\n",
        "\n",
        "\n",
        "**Feature Engineering** is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power. I will carry out feature engineering on different types of variables.\n",
        "\n",
        "\n",
        "First, I will display the categorical and numerical variables again separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "VpMT_jX2zXqj"
      },
      "outputs": [],
      "source": [
        "# check data types in X_train\n",
        "\n",
        "X_train.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "6odKieVrzXqj"
      },
      "outputs": [],
      "source": [
        "# display categorical variables\n",
        "\n",
        "categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n",
        "\n",
        "categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "IO7PIMRjzXqj"
      },
      "outputs": [],
      "source": [
        "# display numerical variables\n",
        "\n",
        "numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
        "\n",
        "numerical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHqzwZ8pzXqj"
      },
      "source": [
        "### Engineering missing values in categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "C9vGjm0vzXqj"
      },
      "outputs": [],
      "source": [
        "# print percentage of missing values in the categorical variables in training set\n",
        "\n",
        "X_train[categorical].isnull().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "4wmEUHvkzXqj"
      },
      "outputs": [],
      "source": [
        "# print categorical variables with missing data\n",
        "\n",
        "for col in categorical:\n",
        "    if X_train[col].isnull().mean()>0:\n",
        "        print(col, (X_train[col].isnull().mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "6H9VKbhuzXqj"
      },
      "outputs": [],
      "source": [
        "# impute missing categorical variables with most frequent value\n",
        "\n",
        "for df2 in [X_train, X_test]:\n",
        "    df2['workclass'].fillna(X_train['workclass'].mode()[0], inplace=True)\n",
        "    df2['occupation'].fillna(X_train['occupation'].mode()[0], inplace=True)\n",
        "    df2['native_country'].fillna(X_train['native_country'].mode()[0], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "gAM2U9nMzXqj"
      },
      "outputs": [],
      "source": [
        "# check missing values in categorical variables in X_train\n",
        "\n",
        "X_train[categorical].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "SerbgG1uzXqk"
      },
      "outputs": [],
      "source": [
        "# check missing values in categorical variables in X_test\n",
        "\n",
        "X_test[categorical].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ulOTZ-azXqk"
      },
      "source": [
        "As a final check, I will check for missing values in X_train and X_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "jpkg1MlszXqk"
      },
      "outputs": [],
      "source": [
        "# check missing values in X_train\n",
        "\n",
        "X_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "TGmPEt69zXqk"
      },
      "outputs": [],
      "source": [
        "# check missing values in X_test\n",
        "\n",
        "X_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGp1dx1izXqk"
      },
      "source": [
        "We can see that there are no missing values in X_train and X_test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg1X9j5JzXqk"
      },
      "source": [
        "### Encode categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "GOk4B3pfzXqk"
      },
      "outputs": [],
      "source": [
        "# print categorical variables\n",
        "\n",
        "categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "v4k8-rp2zXqk"
      },
      "outputs": [],
      "source": [
        "X_train[categorical].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "rw5AB_ZYzXqk"
      },
      "outputs": [],
      "source": [
        "# import category encoders\n",
        "\n",
        "import category_encoders as ce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "OR09S6XHzXqk"
      },
      "outputs": [],
      "source": [
        "# encode remaining variables with one-hot encoding\n",
        "\n",
        "encoder = ce.OneHotEncoder(cols=['workclass', 'education', 'marital_status', 'occupation', 'relationship',\n",
        "                                 'race', 'sex', 'native_country'])\n",
        "\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "\n",
        "X_test = encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "tDtYT7anzXql"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "7zvwr40czXql"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRofA9jgzXql"
      },
      "source": [
        "We can see that from the initial 14 columns, we now have 113 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQSnpQGFzXql"
      },
      "source": [
        "Similarly, I will take a look at the `X_test` set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "iR8eC7eIzXql"
      },
      "outputs": [],
      "source": [
        "X_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "DY_ROIJSzXql"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syv0p9I7zXql"
      },
      "source": [
        "# **11. Feature Scaling** <a class=\"anchor\" id=\"11\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "KPw_-ISIzXql"
      },
      "outputs": [],
      "source": [
        "cols = X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "ERtoEW5vzXql"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "AK_5T5jrzXql"
      },
      "outputs": [],
      "source": [
        "X_train = pd.DataFrame(X_train, columns=[cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "lc2aBvSSzXqm"
      },
      "outputs": [],
      "source": [
        "X_test = pd.DataFrame(X_test, columns=[cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "MeLmFyIKzXqm"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57hIsqyHzXqm"
      },
      "source": [
        "# **12. Model training** <a class=\"anchor\" id=\"12\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "0LXEJOFkzXqm"
      },
      "outputs": [],
      "source": [
        "# train a Gaussian Naive Bayes classifier on the training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "gnb = GaussianNB()\n",
        "\n",
        "\n",
        "# fit the model\n",
        "gnb.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYMELvB4zXqm"
      },
      "source": [
        "# **13. Predict the results** <a class=\"anchor\" id=\"13\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "rdOrqwPKzXqm"
      },
      "outputs": [],
      "source": [
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RGlfTP9zXqm"
      },
      "source": [
        "# **14. Check accuracy score** <a class=\"anchor\" id=\"14\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "9ps4ngsszXqm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf0RJUIbzXqm"
      },
      "source": [
        "### Compare the train-set and test-set accuracy\n",
        "\n",
        "\n",
        "Now, I will compare the train-set and test-set accuracy to check for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "VUbD9fcUzXqm"
      },
      "outputs": [],
      "source": [
        "y_pred_train = gnb.predict(X_train)\n",
        "\n",
        "y_pred_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "kK564EIuzXqm"
      },
      "outputs": [],
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXq2vMjJzXqn"
      },
      "source": [
        "### Check for overfitting and underfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "Ky_znI_YzXqn"
      },
      "outputs": [],
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(gnb.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(gnb.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnGqhx08zXqn"
      },
      "source": [
        "### Compare model accuracy with null accuracy\n",
        "\n",
        "\n",
        "So, the model accuracy is 0.8083. But, we cannot say that our model is very good based on the above accuracy. We must compare it with the **null accuracy**. Null accuracy is the accuracy that could be achieved by always predicting the most frequent class.\n",
        "\n",
        "So, we should first check the class distribution in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "-mH-rqa7zXqn"
      },
      "outputs": [],
      "source": [
        "# check class distribution in test set\n",
        "\n",
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnLvImuYzXqn"
      },
      "source": [
        "We can see that the occurences of most frequent class is 7407. So, we can calculate null accuracy by dividing 7407 by total number of occurences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "66qkdm9pzXqn"
      },
      "outputs": [],
      "source": [
        "# check null accuracy score\n",
        "\n",
        "null_accuracy = (7407/(7407+2362))\n",
        "\n",
        "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "7o7lRhRCzXqn"
      },
      "outputs": [],
      "source": [
        "# Print the Confusion Matrix and slice it into four pieces\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "EQt3pKuyzXqn"
      },
      "outputs": [],
      "source": [
        "# visualize confusion matrix with seaborn heatmap\n",
        "\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
        "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTXphVqezXqn"
      },
      "source": [
        "# **16. Classification metrices** <a class=\"anchor\" id=\"16\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "iRA0h225zXqn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJxacLN1zXqo"
      },
      "source": [
        "### Classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "JFyyc3brzXqo"
      },
      "outputs": [],
      "source": [
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "4N-ymoFyzXqo"
      },
      "outputs": [],
      "source": [
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwAAIXSpzXqo"
      },
      "source": [
        "### Classification error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "0RhIVvkQzXqo"
      },
      "outputs": [],
      "source": [
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification error : {0:0.4f}'.format(classification_error))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "iXGaISLWzXqo"
      },
      "outputs": [],
      "source": [
        "# print precision score\n",
        "\n",
        "precision = TP / float(TP + FP)\n",
        "\n",
        "\n",
        "print('Precision : {0:0.4f}'.format(precision))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "m08TkuE6zXqo"
      },
      "outputs": [],
      "source": [
        "recall = TP / float(TP + FN)\n",
        "\n",
        "print('Recall or Sensitivity : {0:0.4f}'.format(recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYRtl7hLzXqo"
      },
      "source": [
        "### True Positive Rate\n",
        "\n",
        "\n",
        "**True Positive Rate** is synonymous with **Recall**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "Y2r1zZ8uzXqo"
      },
      "outputs": [],
      "source": [
        "true_positive_rate = TP / float(TP + FN)\n",
        "\n",
        "\n",
        "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCYG6-DIzXqo"
      },
      "source": [
        "### False Positive Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "YUHNJjmCzXqo"
      },
      "outputs": [],
      "source": [
        "false_positive_rate = FP / float(FP + TN)\n",
        "\n",
        "\n",
        "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EtPzXyIzXqp"
      },
      "source": [
        "### Specificity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "Xd2TaBxTzXqp"
      },
      "outputs": [],
      "source": [
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print('Specificity : {0:0.4f}'.format(specificity))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y9Ko_5CzXqp"
      },
      "source": [
        "### Support\n",
        "\n",
        "\n",
        "**Support** is the actual number of occurrences of the class in our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an5QA3uMzXqp"
      },
      "source": [
        "# **17. Calculate class probabilities** <a class=\"anchor\" id=\"17\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "xWqdqv_CzXqp"
      },
      "outputs": [],
      "source": [
        "# print the first 10 predicted probabilities of two classes- 0 and 1\n",
        "\n",
        "y_pred_prob = gnb.predict_proba(X_test)[0:10]\n",
        "\n",
        "y_pred_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "DAkIJBIqzXqp"
      },
      "outputs": [],
      "source": [
        "# store the probabilities in dataframe\n",
        "\n",
        "y_pred_prob_df = pd.DataFrame(data=y_pred_prob, columns=['Prob of - <=50K', 'Prob of - >50K'])\n",
        "\n",
        "y_pred_prob_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "9j8aBAbJzXqp"
      },
      "outputs": [],
      "source": [
        "# print the first 10 predicted probabilities for class 1 - Probability of >50K\n",
        "\n",
        "gnb.predict_proba(X_test)[0:10, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "zjvuQ6rQzXqp"
      },
      "outputs": [],
      "source": [
        "# store the predicted probabilities for class 1 - Probability of >50K\n",
        "\n",
        "y_pred1 = gnb.predict_proba(X_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "BMC2yOiyzXqp"
      },
      "outputs": [],
      "source": [
        "# plot histogram of predicted probabilities\n",
        "\n",
        "\n",
        "# adjust the font size\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "\n",
        "# plot histogram with 10 bins\n",
        "plt.hist(y_pred1, bins = 10)\n",
        "\n",
        "\n",
        "# set the title of predicted probabilities\n",
        "plt.title('Histogram of predicted probabilities of salaries >50K')\n",
        "\n",
        "\n",
        "# set the x-axis limit\n",
        "plt.xlim(0,1)\n",
        "\n",
        "\n",
        "# set the title\n",
        "plt.xlabel('Predicted probabilities of salaries >50K')\n",
        "plt.ylabel('Frequency')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "ondB0EhyzXqq"
      },
      "outputs": [],
      "source": [
        "# plot ROC Curve\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred1, pos_label = '>50K')\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "plt.plot(fpr, tpr, linewidth=2)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--' )\n",
        "\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "plt.title('ROC curve for Gaussian Naive Bayes Classifier for Predicting Salaries')\n",
        "\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "\n",
        "plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoOzJ_RCzXqq"
      },
      "source": [
        "ROC curve help us to choose a threshold level that balances sensitivity and specificity for a particular context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "HOAE6BpIzXqq"
      },
      "outputs": [],
      "source": [
        "# compute ROC AUC\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "ROC_AUC = roc_auc_score(y_test, y_pred1)\n",
        "\n",
        "print('ROC AUC : {:.4f}'.format(ROC_AUC))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "TwkBiCv7zXqq"
      },
      "outputs": [],
      "source": [
        "# calculate cross-validated ROC AUC\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "Cross_validated_ROC_AUC = cross_val_score(gnb, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
        "\n",
        "print('Cross validated ROC AUC : {:.4f}'.format(Cross_validated_ROC_AUC))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlBS4XZIzXqq"
      },
      "source": [
        "# **19. k-Fold Cross Validation** <a class=\"anchor\" id=\"19\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "wLqPJgglzXqq"
      },
      "outputs": [],
      "source": [
        "# Applying 10-Fold Cross Validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(gnb, X_train, y_train, cv = 10, scoring='accuracy')\n",
        "\n",
        "print('Cross-validation scores:{}'.format(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otTqF66xzXqq"
      },
      "source": [
        "We can summarize the cross-validation accuracy by calculating its mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "ubxml6ZpzXqq"
      },
      "outputs": [],
      "source": [
        "# compute Average cross-validation score\n",
        "\n",
        "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqtZZKqSzXqq"
      },
      "source": [
        "# **20. Results and conclusion** <a class=\"anchor\" id=\"20\"></a>\n",
        "\n",
        "[Table of Contents](#0.1)\n",
        "\n",
        "\n",
        "1.\tIn this project, I build a Gaussian Naïve Bayes Classifier model to predict whether a person makes over 50K a year. The model yields a very good performance as indicated by the model accuracy which was found to be 0.8083.\n",
        "2.\tThe training-set accuracy score is 0.8067 while the test-set accuracy to be 0.8083. These two values are quite comparable. So, there is no sign of overfitting.\n",
        "3.\tI have compared the model accuracy score which is 0.8083 with null accuracy score which is 0.7582. So, we can conclude that our Gaussian Naïve Bayes classifier model is doing a very good job in predicting the class labels.\n",
        "4.\tROC AUC of our model approaches towards 1. So, we can conclude that our classifier does a very good job in predicting whether a person makes over 50K a year.\n",
        "5.\tUsing the mean cross-validation, we can conclude that we expect the model to be around 80.63% accurate on average.\n",
        "6.\tIf we look at all the 10 scores produced by the 10-fold cross-validation, we can also conclude that there is a relatively small variance in the accuracy between folds, ranging from 81.35% accuracy to 79.64% accuracy. So, we can conclude that the model is independent of the particular folds used for training.\n",
        "7.\tOur original model accuracy is 0.8083, but the mean cross-validation accuracy is 0.8063. So, the 10-fold cross-validation accuracy does not result in performance improvement for this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjngRe18zXqr"
      },
      "source": [
        "[Go to Top](#0)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 86608,
          "sourceId": 199574,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 29849,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}